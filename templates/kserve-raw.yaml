apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  annotations:
    serving.kserve.io/deploymentMode: RawDeployment
  name: whisper-small-kserve-raw
spec:
  predictor:
    containers:
      - name: kserve-container
        image: quay.io/cfchase/asr-runtime:latest
        imagePullPolicy: Always
        resources:
          limits:
            cpu: '14'
            memory: 8Gi
            nvidia.com/gpu: 1
          requests:
            cpu: '2'
            memory: 4Gi
            nvidia.com/gpu: 1
        env:
          - name: MODEL_ID
            value: 'openai/whisper-small'
    tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule

